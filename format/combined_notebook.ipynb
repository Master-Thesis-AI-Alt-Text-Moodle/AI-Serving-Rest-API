{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1e5761",
   "metadata": {},
   "source": [
    "# File: api\\alt_text.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df952762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import APIRouter, Depends, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from models.blip_base import BLIPBase\n",
    "from utils.image_processing import decode_base64_image\n",
    "from .auth import get_api_key\n",
    "import logging\n",
    "from fastapi import Request\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Union\n",
    "from fastapi import APIRouter, Depends, HTTPException, Request\n",
    "from models.blip_base import BLIPBase\n",
    "from utils.image_processing import decode_base64_image\n",
    "import logging\n",
    "import base64\n",
    "from typing import Dict\n",
    "import asyncio\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "router = APIRouter()\n",
    "model = BLIPBase()\n",
    "\n",
    "\n",
    "\n",
    "class ImageUrl(BaseModel):\n",
    "    url: str\n",
    "    detail: str = None\n",
    "\n",
    "class Content(BaseModel):\n",
    "    type: str\n",
    "    text: str = None\n",
    "    image_url: ImageUrl = None\n",
    "\n",
    "class Message(BaseModel):\n",
    "    role: str\n",
    "    content: List[Content]\n",
    "\n",
    "class AltTextRequest(BaseModel):\n",
    "    model: str\n",
    "    messages: List[Message]\n",
    "    max_tokens: int\n",
    "\n",
    "\n",
    "\n",
    "class AltTextResponse(BaseModel):\n",
    "    choices: List[dict]\n",
    "\n",
    "class AltTextResponse(BaseModel):\n",
    "    choices: List[Dict[str, Dict[str, str]]]\n",
    "\n",
    "async def generate_alt_text_with_timeout(image, prompt, timeout=30):\n",
    "    try:\n",
    "        return await asyncio.wait_for(\n",
    "            asyncio.to_thread(model.generate_alt_text, image, prompt),\n",
    "            timeout=timeout\n",
    "        )\n",
    "    except asyncio.TimeoutError:\n",
    "        raise HTTPException(status_code=504, detail=\"Alt text generation timed out\")\n",
    "\n",
    "@router.post(\"/generate_alt_text\", response_model=AltTextResponse)\n",
    "async def generate_alt_text(request: AltTextRequest, api_key: str = Depends(get_api_key)):\n",
    "    try:\n",
    "        logger.info(f\"Received request: {request}\")\n",
    "\n",
    "        # Extract image and prompt from the request\n",
    "        content = request.messages[0].content\n",
    "        prompt = next(item.text for item in content if item.type == 'text')\n",
    "        image_url = next(item.image_url.url for item in content if item.type == 'image_url')\n",
    "\n",
    "        logger.info(f\"Extracted prompt: {prompt}\")\n",
    "        logger.info(f\"Extracted image URL (first 100 chars): {image_url[:100]}\")\n",
    "\n",
    "        # Decode base64 image\n",
    "        image = decode_base64_image(image_url)\n",
    "\n",
    "        # Generate alt text\n",
    "        alt_text = await generate_alt_text_with_timeout(image, prompt)\n",
    "\n",
    "        # Format response to match OpenAI's format\n",
    "        response = {\n",
    "            \"choices\": [\n",
    "                {\n",
    "                    \"message\": {\n",
    "                        \"content\": alt_text\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating alt text: {str(e)}\", exc_info=True)\n",
    "        raise HTTPException(status_code=500, detail=f\"Error generating alt text: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1e852",
   "metadata": {},
   "source": [
    "# File: api\\auth.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1dc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import Security, HTTPException, status\n",
    "from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer\n",
    "from utils.config import settings\n",
    "\n",
    "security = HTTPBearer()\n",
    "\n",
    "async def get_api_key(credentials: HTTPAuthorizationCredentials = Security(security)):\n",
    "    if credentials.credentials == settings.API_KEY:\n",
    "        return credentials.credentials\n",
    "    raise HTTPException(\n",
    "        status_code=status.HTTP_403_FORBIDDEN, detail=\"Could not validate API key\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21cbaa2",
   "metadata": {},
   "source": [
    "# File: main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3efaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from fastapi import FastAPI\n",
    "from api import auth, alt_text\n",
    "from utils.config import settings\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import logging\n",
    "from fastapi import Request\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = FastAPI(title=settings.PROJECT_NAME)\n",
    "\n",
    "\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allows all origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Allows all methods\n",
    "    allow_headers=[\"*\"],  # Allows all headers\n",
    ")\n",
    "\n",
    "from fastapi.exceptions import RequestValidationError\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "@app.exception_handler(RequestValidationError)\n",
    "async def validation_exception_handler(request: Request, exc: RequestValidationError):\n",
    "    logger.error(f\"Validation error: {exc.errors()}\")\n",
    "    return JSONResponse(\n",
    "        status_code=422,\n",
    "        content={\"detail\": exc.errors(), \"body\": exc.body},\n",
    "    )\n",
    "\n",
    "app.include_router(alt_text.router, prefix=settings.API_V1_STR, tags=[\"alt_text\"])\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    logger.info(\"Starting up the application\")\n",
    "\n",
    "@app.on_event(\"shutdown\")\n",
    "async def shutdown_event():\n",
    "    logger.info(\"Shutting down the application\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c27b3",
   "metadata": {},
   "source": [
    "# File: models\\blip_base.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import BlipForConditionalGeneration, BlipProcessor\n",
    "from models.model_interface import ModelInterface\n",
    "from utils.config import settings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class BLIPBase(ModelInterface):\n",
    "    def __init__(self):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model_name = \"Salesforce/blip-image-captioning-base\"\n",
    "        \n",
    "        # Check if the model is already downloaded\n",
    "        if not os.path.exists(settings.BLIP_MODEL_PATH):\n",
    "            logger.info(f\"BLIP model not found at {settings.BLIP_MODEL_PATH}. Downloading...\")\n",
    "            self.download_model()\n",
    "        \n",
    "        logger.info(f\"Loading BLIP model from {settings.BLIP_MODEL_PATH}\")\n",
    "        self.processor = BlipProcessor.from_pretrained(settings.BLIP_MODEL_PATH)\n",
    "        self.model = BlipForConditionalGeneration.from_pretrained(settings.BLIP_MODEL_PATH).to(self.device)\n",
    "        logger.info(\"BLIP model loaded successfully\")\n",
    "\n",
    "    def download_model(self):\n",
    "        try:\n",
    "            # This will download and cache the model\n",
    "            processor = BlipProcessor.from_pretrained(self.model_name)\n",
    "            model = BlipForConditionalGeneration.from_pretrained(self.model_name)\n",
    "            \n",
    "            # Save the model to the specified path\n",
    "            os.makedirs(settings.BLIP_MODEL_PATH, exist_ok=True)\n",
    "            processor.save_pretrained(settings.BLIP_MODEL_PATH)\n",
    "            model.save_pretrained(settings.BLIP_MODEL_PATH)\n",
    "            \n",
    "            logger.info(f\"BLIP model downloaded and saved to {settings.BLIP_MODEL_PATH}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error downloading BLIP model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def generate_alt_text(self, image: Image.Image, prompt: str) -> str:\n",
    "        prompt = \"\"\n",
    "        try:\n",
    "            logger.info(f\"Generating alt text for image size: {image.size}\")\n",
    "            inputs = self.processor(image, prompt, return_tensors=\"pt\").to(self.device)\n",
    "            logger.info(\"Processed image with BLIP processor\")\n",
    "            output = self.model.generate(**inputs)\n",
    "            logger.info(\"Generated output from BLIP model\")\n",
    "            return self.processor.decode(output[0], skip_special_tokens=True)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in generate_alt_text: {str(e)}\", exc_info=True)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb8000",
   "metadata": {},
   "source": [
    "# File: models\\model_interface.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from PIL import Image\n",
    "\n",
    "class ModelInterface(ABC):\n",
    "    @abstractmethod\n",
    "    def generate_alt_text(self, image: Image.Image, prompt: str) -> str:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08622724",
   "metadata": {},
   "source": [
    "# File: utils\\config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic_settings import BaseSettings\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    API_V1_STR: str = \"/api/v1\"\n",
    "    PROJECT_NAME: str = \"Moodle Alt Text API\"\n",
    "    ALGORITHM: str = \"HS256\"\n",
    "    API_KEY: str = os.getenv(\"API_KEY\", \"your-default-api-key\")\n",
    "    BLIP_MODEL_PATH: str = os.getenv(\"BLIP_MODEL_PATH\", os.path.expanduser(\"~/.cache/huggingface/blip-base\"))\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59153b2",
   "metadata": {},
   "source": [
    "# File: utils\\image_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def decode_base64_image(base64_string):\n",
    "    try:\n",
    "        # Remove the \"data:image/png;base64,\" part if it exists\n",
    "        if 'base64,' in base64_string:\n",
    "            base64_string = base64_string.split('base64,')[1]\n",
    "        \n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        logger.info(f\"Decoded image data length: {len(image_data)}\")\n",
    "        \n",
    "        image = Image.open(BytesIO(image_data))\n",
    "        logger.info(f\"Image opened successfully. Format: {image.format}, Size: {image.size}, Mode: {image.mode}\")\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error decoding base64 image: {str(e)}\")\n",
    "        logger.error(f\"First 100 characters of base64 string: {base64_string[:100]}\")\n",
    "        raise\n",
    "\n",
    "def encode_image_to_base64(image: Image.Image) -> str:\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
